ninja  # For faster builds.
psutil
ray >= 2.9
sentencepiece  # Required for LLaMA tokenizer.
numpy
# https://stackoverflow.com/questions/2477117/pip-requirements-txt-with-alternative-index
--extra-index-url https://download.pytorch.org/whl/cu118
torch == 2.1.2
transformers >= 4.37.0 # Required for Qwen2
--extra-index-url https://download.pytorch.org/whl/cu118
xformers == 0.0.23.post1  # Required for CUDA 12.1.
fastapi
uvicorn[standard]
pydantic >= 2.0  # Required for OpenAI server.
aioprometheus[starlette]
pynvml == 11.5.0
triton >= 2.1.0
# cupy-cuda12x == 12.1.0  # Required for CUDA graphs. CUDA 11.8 users should install cupy-cuda11x instead.
cupy-cuda11x == 12.1.0
timm
https://github.com/vllm-project/vllm/releases/download/v0.3.1/vllm-0.3.1+cu118-cp310-cp310-manylinux1_x86_64.whl